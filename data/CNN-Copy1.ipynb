{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainModel import *\n",
    "from torchData iqmport duneADCdata\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "# from simpleCNN import Net\n",
    "from torchvision import datasets, transforms\n",
    "from torchData import duneADCdata, ToTensor\n",
    "torch.manual_seed(1516989)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchData import duneADCdata, ToTensor\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5,stride=1, padding=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=5,stride=2,padding=2)\n",
    "        self.batchnorm =  nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32 , kernel_size=3)\n",
    "        self.fc1 = nn.Linear(int(1500*1500*2),128)#int(1500*1500*0.25), 120)\n",
    "        self.fc2 = nn.Linear(128, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        self.drop = nn.Dropout2d(p=0.05)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.drop(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = F.softmax(self.fc3(x))\n",
    "#         print(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32913\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([ToTensor()])\n",
    "batch_size =64\n",
    "n_epochs=10\n",
    "classes = [\"radio\",\"SNB\"]\n",
    "# data = duneADCdata(\"seconddata_cp.csv\", \"./\", transform=transform)\n",
    "# data = duneADCdata(\"bigdata_new.csv\", \"./\", transform=transform)\n",
    "data = duneADCdata(\"finalData.csv\", \"./\", transform=transform)\n",
    "\n",
    "# data = data[0:1000]\n",
    "\n",
    "print(len(data))\n",
    "lengths = [int(len(data)*0.8),int(len(data))-int(len(data)*0.8)]\n",
    "trainData, testData= random_split(data,lengths)\n",
    "trainLoader = DataLoader(trainData, batch_size=batch_size, shuffle=True,num_workers=14)\n",
    "testLoader = DataLoader(testData, batch_size=batch_size, shuffle=True,num_workers=14)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9,weight_decay=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "[                                                                                                                                                                                                                                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewis/.conda/envs/SparseAIEnv/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.711\n",
      "[1,     2] loss: 0.659\n",
      "[1,     3] loss: 0.623\n",
      "[1,     4] loss: 0.580\n",
      "[1,     5] loss: 0.548\n",
      "[1,     6] loss: 0.502\n",
      "[1,     7] loss: 0.515\n",
      "[1,     8] loss: 0.458\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f98f3cd77d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNNloss.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/data/trainModel.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, optimizer, batch_size, n_epochs, model_fname, learning_rate)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#             print(labels.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m#             print(outputs.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/SparseAIEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-68eb37559d11>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/SparseAIEnv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net,losses = train(net, trainLoader, optimizer, n_epochs=n_epochs,batch_size=batch_size)\n",
    "np.savetxt(\"CNNloss.txt\",losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"./model/model.pth\"))\n",
    "losses = np.loadtxt(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "avg_losses = np.mean(np.reshape(np.array(losses),(409,-1)),axis=1)\n",
    "print(avg_losses)\n",
    "plt.plot(avg_losses)\n",
    "# plt.plot(losses)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n",
    "plt.show()\n",
    "plt.savefig(\"CNNloss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testLoader)\n",
    "true = []\n",
    "predict = []\n",
    "for data in dataiter:\n",
    "    images = data['input']\n",
    "    labels = data['target']\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "    predict.append(predicted)\n",
    "    true.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "snb = 0\n",
    "radio = 0\n",
    "outs = []\n",
    "labs = []\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        images = data['input']\n",
    "        labels = data['target']\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        outs.append(outputs.data)\n",
    "        labs.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        snb += (predicted == 1).sum().item()\n",
    "        radio += (predicted == 0).sum().item()\n",
    "\n",
    "    \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(\"SNB: {}\".format(snb))\n",
    "print(\"Radio: {}\".format(radio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "        images = data['input']\n",
    "        labels = data['target']\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            if predicted[i] != labels[i]:\n",
    "                plt.imshow(images[i].reshape((1500,1500)))\n",
    "                plt.title(\"Predicted: {}\\nActual: {}\\nScore: {}%\".format(predicted[i],labels[i],outputs[i][predicted[i]]*100))\n",
    "                plt.show()\n",
    "                print(images[i].reshape((1500,1500)))\n",
    "        for i in range(2):\n",
    "            label = classes[i]\n",
    "            class_correct[i] += c[i].item()\n",
    "            class_total[i] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %5d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "df_cm = pd.DataFrame(cm, range(6), range(6))\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sn\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "Y_test = torch.cat(labs).numpy()\n",
    "ns_probs = [0 for _ in range(len(Y_test))]\n",
    "lr_probs = torch.cat(outs).numpy()[:,1]\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "# lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(Y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(Y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(Y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.',markersize=2,linewidth=1, label='CNN')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "# plt.show()\n",
    "plt.savefig(\"CNNroc1.png\",dpi=500,bbox_inches='tight')\n",
    "# plt.xlim(0,0.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from tensorboard.summary.writer.record_writer import RecordWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(\"runs/CNN\")\n",
    "# import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.facebook.com/groups/2009507865950023/permalink/2716336138600522/dataiter = iter(trainLoader)\n",
    "data = dataiter.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer.add_graph(net, data['input'])\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from Andreas Sogaard DAML helper code\n",
    "# from . import plot\n",
    "# from . import utilities    as _utilities\n",
    "# from . import optimisation as _optimisation\n",
    "# from . import _internal# from . import optimisation\n",
    "\n",
    "def roc (*clfs, y=None, pred=None, target_eff=0.5, scale='log',xlim=[0,1]):\n",
    "    \"\"\"\n",
    "    Plot the so-called receiver operating characteristic (ROC) curve(s) for the \n",
    "    classifier(s) `clfs`.\n",
    "    \n",
    "    Arguments:\n",
    "        clfs: Variable-length list of scikit-learn classifiers, such as \n",
    "            sklearn.neural_network.MLPClassifier, or Keras networks, of type \n",
    "            keras.models.Model. The classifiers are assumed to have been fitted \n",
    "            on the same set of features to classify only two target classes \n",
    "            either using their respective  `fit`-methods, or using the \n",
    "            `utilities.fit` method. These are specified in the function call as \n",
    "            e.g.:\n",
    "            ```\n",
    "            plot.roc(clf1, clf2, clf3, X=X_test, y=y_test);\n",
    "            ```\n",
    "            *Please note* that the remaining arguments have to be specified as \n",
    "            keywords, i.e. using the `..., kw=<something>, ...` syntax suggested \n",
    "            above.\n",
    "        X: numpy.array, of shape (nb_samples, nb_features), containing the array \n",
    "            of features on which the classifier(s) should be evaluated.\n",
    "        y: numpy.array, of shape (nb_samples, 1), containing the list targets \n",
    "            classes, assumed to be either 0 or 1.\n",
    "        target_eff: Float, the target signal (y = 1) efficiency at which the \n",
    "            corresponding background rejection rate should be evaluated.\n",
    "        scale: String, either 'log' or 'linear', specifying the type of y-axis \n",
    "            scale to draw.\n",
    "            \n",
    "    Raises:\n",
    "        AssertionError, if any of the checks fail.\n",
    "        \n",
    "    Returns:\n",
    "        pyplot.figure containing the ROC curve plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check(s)\n",
    "#     assert X is not None, \\\n",
    "#         \"Please specify a testing dataset, `X`.\"\n",
    "    assert y is not None, \\\n",
    "        \"Please specify true labels, `y`.\"\n",
    "#     assert X.shape[0] == y.shape[0]\n",
    "    assert len(y.squeeze().shape) == 1\n",
    "    \n",
    "    # Import(s)\n",
    "    from sklearn.metrics import roc_curve    \n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    \n",
    "    # Random guessing line\n",
    "    tpr = np.linspace(0, 1, 200 + 1, endpoint=True)[1:]\n",
    "    ax.plot(tpr, 1./tpr, ls='--', c=\"blue\",label='No Skill')\n",
    "    \n",
    "    # ROC curves\n",
    "    rocs = list()\n",
    "    for clf in clfs:\n",
    "#         pred = get_output(clf, X)\n",
    "        sign = 1. if pred[y == 1].mean() > pred[y == 0].mean() else -1.\n",
    "        fpr, tpr, _ = roc_curve(y, sign * pred)\n",
    "        \n",
    "        # Filter out entries with no background passing\n",
    "        msk = (fpr > 0)\n",
    "        tpr = tpr[msk]\n",
    "        fpr = fpr[msk]\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        ax.plot(tpr, 1./fpr, c=\"orange\",marker=\".\")#, label=_utilities.get_network_name(clf))\n",
    "        \n",
    "        # Store efficiency arrays\n",
    "        rocs.append((tpr, fpr))\n",
    "        pass\n",
    "    \n",
    "    # Indicate best result\n",
    "    best_rejection = -np.inf\n",
    "    best_clfs      = []\n",
    "    ax.axvline(target_eff, c='darkgray', ls=':', lw=1)\n",
    "    for ix, (clf, (tpr, fpr)) in enumerate(zip(clfs, rocs)):\n",
    "        if target_eff < tpr.min():\n",
    "            print(\"No valid background rejection rate at target efficiency ({:.0f}%) for model: {}\")#.format(target_eff * 100., _utilities.get_network_name(clf)))\n",
    "            best_rejection = np.inf\n",
    "            best_clfs.append(ix)\n",
    "            continue\n",
    "            \n",
    "        rejection = np.interp(target_eff, tpr, 1./fpr)\n",
    "      \n",
    "        if rejection > best_rejection:\n",
    "            best_rejection = rejection\n",
    "            best_clfs.append(ix)\n",
    "            pass\n",
    "        pass\n",
    "         \n",
    "    # Decorations\n",
    "    ax.set_yscale(scale)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xlabel(\"Signal efficiency\")\n",
    "    ax.set_ylabel(\"Background rejection factor\")\n",
    "   \n",
    "    if not np.isinf(best_rejection):\n",
    "        frac = 0.03\n",
    "        \n",
    "        x = target_eff\n",
    "        y = best_rejection\n",
    "        y1, y2 = ax.get_ylim()\n",
    "        \n",
    "        logyDraw = (np.log10(y) - np.log10(y1) + frac * (np.log10(y2) - np.log10(y1))) + np.log10(y1)\n",
    "\n",
    "        xDraw = x - frac * (1. - 0.)\n",
    "        yDraw = np.power(10, logyDraw)\n",
    "\n",
    "        ax.plot(target_eff, best_rejection, 'r*')\n",
    "        digits = 1 if best_rejection < 100 else 0\n",
    "        ax.text(xDraw, yDraw, f'x{{:.{digits}f}}'.format(best_rejection), fontdict={'weight': 600})\n",
    "        pass\n",
    "    \n",
    "    # Draw legend and boldface the best instance(s)\n",
    "    l = ax.legend()\n",
    "    plt.xlim(xlim)\n",
    "    for ix, text in enumerate(l.get_texts()[1:]):\n",
    "        if ix in best_clfs:\n",
    "            text._fontproperties = l.get_texts()[0]._fontproperties.copy()\n",
    "            text.set_weight(600)\n",
    "            pass\n",
    "        pass\n",
    "   \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lr_probs))\n",
    "f = roc(net,y=Y_test,pred=lr_probs,target_eff=0.971,scale='log',xlim=[0.8,1])\n",
    "# plt.show()\n",
    "f.savefig(\"CNNroc2.png\",bbox_inches='tight',dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SparseAIEnv",
   "language": "python",
   "name": "sparseaienv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
